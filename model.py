import tensorflow as tf
import numpy as np
import os
from tensorflow.examples.tutorials import mnist

class DrawRNN:
    def __init__(self):
        """ Parameter Init
        """
        self.height = 28
        self.width = 28
        self.batch_size = 16
        self.grid_n = 5
        self.latent_size = 10
        self.lr = 1e-3
        self.T = 10  # Sequence Iterations
        self.encoder_size = 128
        self.decoder_size = 128
        self.eps = 1e-8 # Epsilon
        self.reuse = None

        """ Input
        """
        self.input_size = self.height*self.width
        self.x = tf.placeholder(tf.float32, [self.batch_size, self.input_size])
        self.sampler = tf.random_normal([self.batch_size, self.latent_size], mean=0, stddev=1.0)

        """ LSTM Cells
        """
        self.encoder_cell = tf.nn.rnn_cell.LSTMCell(self.encoder_size)
        self.decoder_cell = tf.nn.rnn_cell.LSTMCell(self.decoder_size)
        self.read = self.read_attention
        self.write = self.write_attention
        self.canvas_seq = [0]*self.T # sequence of canvas
        self.mu_seq = [0]*self.T # gaussian params generated by SampleQ. We will need these for computing loss.
        self.log_sigma_seq = [0]*self.T
        self.sigma_seq = [0]*self.T

        """ Initial States
        """
        self.h_dec_prev = tf.zeros((self.batch_size, self.decoder_size))
        self.enc_state = self.encoder_cell.zero_state(self.batch_size, tf.float32)
        self.dec_state = self.decoder_cell.zero_state(self.batch_size, tf.float32)

        """ Main Computation
        """
        self._unrolled_graph()
        self.x_reconstructed = tf.nn.sigmoid(self.canvas_seq[-1])

        """ Loss
        """
        self.loss_reconstruction = tf.reduce_sum(self.binary_crossentropy(self.x, self.x_reconstructed), 1) # reconstruction term
        self.loss_reconstruction = tf.reduce_mean(self.loss_reconstruction)
        self.loss_kl_divergence = self.KL_divergence()
        self.loss_total = self.loss_kl_divergence + self.loss_reconstruction

        tf.summary.scalar('kl-loss', self.loss_kl_divergence)
        tf.summary.scalar('reconstruction-loss', self.loss_reconstruction)
        tf.summary.scalar('loss', self.loss_total)
        self.summary_op = tf.summary.merge_all()
        self.summary_writer = tf.summary.FileWriter("logs/", graph=tf.get_default_graph())

        """ OptimizerOP
        """
        optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)
        grads = optimizer.compute_gradients(self.loss_total)
        for i, (g, v) in enumerate(grads):
            if g is not None:
                grads[i] = (tf.clip_by_norm(g, 5), v) # clip gradients
        self.train_op = optimizer.apply_gradients(grads)

        self.data_dir = "./mnist"
        self.saver = tf.train.Saver() # saves variables learned during training

    def encode(self, state, input_):
        """
        run LSTM
        state = previous encoder state
        input = cat(read,h_dec_prev)
        returns: (output, new_state)
        """
        with tf.variable_scope("encoder",reuse=self.reuse):
            return self.encoder_cell(input_, state)

    def sampleQ(self, h_enc):
        """
        Samples Zt ~ normrnd(mu,sigma) via reparameterization trick for normal dist
        mu is (batch,z_size)
        """
        with tf.variable_scope("mu",reuse=self.reuse):
            mu = self._linear(h_enc, self.latent_size)
        with tf.variable_scope("sigma",reuse=self.reuse):
            logsigma = self._linear(h_enc, self.latent_size)
            sigma = tf.exp(logsigma)
        return (mu + sigma*self.sampler, mu, logsigma, sigma)

    def decode(self, state, input_):
        with tf.variable_scope("decoder",reuse=self.reuse):
            return self.decoder_cell(input_, state)

    def train(self, num_epoch):
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)

        train_iters = num_epoch
        train_data = mnist.input_data.read_data_sets(self.data_dir, one_hot=True).train # binarized (0-1) mnist data

        fetches = []
        fetches.extend([self.loss_reconstruction, self.loss_kl_divergence, self.summary_op, self.train_op])

        sess = tf.InteractiveSession()

        tf.global_variables_initializer().run()
        ckpt_file = os.path.join(self.data_dir, "drawmodel.ckpt")
        self.saver.restore(sess, ckpt_file) # to restore from model, uncomment this line
        #try:
        #    self.saver.restore(sess, ckpt_file) # to restore from model, uncomment this line
        #except:
        #    print("No model found! Saving new model...")

        for i in range(train_iters):
            xtrain, _ = train_data.next_batch(self.batch_size) # xtrain is (batch_size x img_size)
            feed_dict = {self.x:xtrain}
            results = sess.run(fetches, feed_dict)
            Lxs, Lzs, summary, _ = results
            if i%100 ==0:
                print("iter=%d : Lx: %f Lz: %f" % (i,Lxs,Lzs))
            if i%10 == 0:
                self.summary_writer.add_summary(summary, i)

        ## TRAINING FINISHED ##

        canvases = sess.run(self.canvas_seq , feed_dict) # generate some examples
        canvases = np.array(canvases) # T x batch x img_size

        out_file = os.path.join(self.data_dir, "draw_data.npy")
        np.save(out_file, [canvases,Lxs,Lzs])
        print("Outputs saved in file: %s" % out_file)

        print("Model saved in file: %s" % self.saver.save(sess,ckpt_file))
        sess.close()

    def KL_divergence(self):
        kl_terms = [0]*self.T
        for t in range(self.T):
            mu2 = tf.square(self.mu_seq[t])
            sigma2 = tf.square(self.sigma_seq[t])
            logsigma = self.log_sigma_seq[t]
            kl_terms[t] = 0.5*tf.reduce_sum(mu2 + sigma2 - 2*logsigma, 1) - 0.5 # each kl term is (1xminibatch)
        KL = tf.add_n(kl_terms) # this is 1xminibatch, corresponding to summing kl_terms from 1:T
        Lz = tf.reduce_mean(KL) # average over minibatches
        return Lz

    def _unrolled_graph(self):
        """ Construct the unrolled computational graph
        """
        for t in range(self.T):
            if t == 0:
                c_prev = tf.zeros((self.batch_size,self.height*self.width))
            else:
                c_prev = self.canvas_seq[t-1]
            x_hat = self.x - tf.sigmoid(c_prev) # error image
            r = self.read(self.x, x_hat, self.h_dec_prev)
            h_enc, self.enc_state = self.encode(self.enc_state, tf.concat([r,self.h_dec_prev], 1))
            z, self.mu_seq[t], self.log_sigma_seq[t], self.sigma_seq[t] = self.sampleQ(h_enc)
            h_dec, self.dec_state = self.decode(self.dec_state, z)
            self.canvas_seq[t] = c_prev + self.write(h_dec) # store results
            self.h_dec_prev = h_dec
            self.reuse = True

    def binary_crossentropy(self, t, output):
        return -(t*tf.log(output + self.eps) + (1.0 - t)*tf.log(1.0 - output + self.eps))

    def _linear(self, x, y_dim):
        """ Linear Weight Multiplication
        """
        w = tf.get_variable(name='w', shape=[x.shape[1], y_dim])
        b = tf.get_variable(name='b', shape=[y_dim], initializer=tf.constant_initializer(0.0))
        return tf.matmul(x,w) + b

    def _filter_bank(self, gx, gy, sigma_sqr, delta):
        """ Applying Gaussian Filters with four Attention Parameters
            input = gx, gy, sigma_square, delta
            output = Fx, Fy : Filter outputs
        """
        patch_index = tf.reshape(tf.cast(tf.range(self.grid_n), tf.float32), [1, -1])
        a = tf.reshape(tf.cast(tf.range(self.width), tf.float32), [1, -1])
        b = tf.reshape(tf.cast(tf.range(self.height), tf.float32), [1, -1])
        mu_x = gx + (patch_index - self.grid_n/2.0 - 0.5)*delta
        mu_y = gy + (patch_index - self.grid_n/2.0 - 0.5)*delta
        mu_x = tf.reshape(mu_x, [-1, self.grid_n, 1])
        mu_y = tf.reshape(mu_y, [-1, self.grid_n, 1])
        sigma_sqr = tf.reshape(sigma_sqr, [-1, 1, 1])
        Fx = tf.exp(-tf.square(a - mu_x) / (2*sigma_sqr)) # batch x N x width
        Fy = tf.exp(-tf.square(b - mu_y) / (2*sigma_sqr)) # batch x N x height
        # normalize, sum over A and B dims
        Fx = Fx/tf.maximum(tf.reduce_sum(Fx,axis=2,keepdims=True),self.eps)
        Fy = Fy/tf.maximum(tf.reduce_sum(Fy,axis=2,keepdims=True),self.eps)
        return Fx, Fy

    def _attention_window(self, h_dec, scope):
        with tf.variable_scope(scope, reuse=self.reuse):
            params = self._linear(h_dec,5)

        gx_, gy_, log_sigma_sqr, log_delta, log_gamma = tf.split(params,5,1)
        gx = (self.width + 1)/2*(gx_ + 1)
        gy = (self.height + 1)/2*(gy_ + 1)
        sigma_sqr = tf.exp(log_sigma_sqr)
        delta = (max(self.width, self.height) - 1)/(self.grid_n - 1) * tf.exp(log_delta) # batch x N

        return self._filter_bank(gx, gy, sigma_sqr, delta) + (tf.exp(log_gamma),)

    def read_without_attention(self, x,x_hat,h_dec_prev):
        return tf.concat([x,x_hat], 1)

    def read_attention(self, x, x_hat, h_dec_prev):
        Fx, Fy, gamma = self._attention_window(h_dec_prev, scope = "read")
        x = self._filter_img(x,Fx,Fy,gamma) # batch x (grid_n*grid_n)
        x_hat = self._filter_img(x_hat,Fx,Fy,gamma)
        return tf.concat([x, x_hat], 1) # concat along feature axis

    def _filter_img(self, img, Fx, Fy, gamma):
        Fxt = tf.transpose(Fx,[0,2,1])
        img = tf.reshape(img,[-1, self.height, self.width])
        glimpse = tf.matmul(Fy, tf.matmul(img, Fxt))
        glimpse = tf.reshape(glimpse, [-1,self.grid_n*self.grid_n])
        return glimpse*tf.reshape(gamma, [-1,1])

    def write_without_attention(self, h_dec):
        with tf.variable_scope("write", reuse = self.reuse):
            return self._linear(h_dec, self.height*self.width)

    def write_attention(self, h_dec):
        with tf.variable_scope("writeW", reuse = self.reuse):
            w = self._linear(h_dec, self.grid_n*self.grid_n)
        w = tf.reshape(w, [self.batch_size, self.grid_n, self.grid_n])
        Fx, Fy, gamma = self._attention_window(h_dec, scope = "write")
        Fyt = tf.transpose(Fy, [0,2,1])
        wr = tf.matmul(Fyt, tf.matmul(w,Fx))
        wr = tf.reshape(wr,[self.batch_size,self.width*self.height])
        #gamma=tf.tile(gamma,[1,B*A])
        return wr*tf.reshape(1.0/gamma,[-1,1])

